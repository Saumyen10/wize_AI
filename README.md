                                                                ğ–ğğ› ğ’ğœğ«ğšğ©ğ¢ğ§ğ , ğƒğšğ­ğš ğ‚ğ¥ğğšğ§ğ¢ğ§ğ  ğšğ§ğ ğ“ğ¨ğ©ğ¢ğœ ğ‚ğ¥ğšğ¬ğ¬ğ¢ğŸğ¢ğœğšğ­ğ¢ğ¨ğ§ ğğ¢ğ©ğğ¥ğ¢ğ§ğ:

ğğ«ğ¨ğ£ğğœğ­ ğğ¯ğğ«ğ¯ğ¢ğğ°:
This project implements a pipeline to scrape articles by a specific author, clean the data, and classify topics using Natural Language Processing (NLP). The pipeline processes articles for a well-organized dataset structured around key themes.

ğ…ğğšğ­ğ®ğ«ğğ¬--->

Web Scraping: Extracts articles written by a specific author across multiple pages, handling pagination and dynamic loading.

Data Cleaning: Processes and cleans text to remove irrelevant content, normalize formatting, and standardize metadata.

Topic Classification: Categorizes articles into predefined topics, utilizing NLP techniques for accurate classification.


ğ‘ğğªğ®ğ¢ğ«ğğ¦ğğ§ğ­ğ¬:

Programming Language: Python 


ğ‹ğ¢ğ›ğ«ğšğ«ğ¢ğğ¬:

requests, BeautifulSoup4: For web scraping.

pandas: For data manipulation and storage.

sklearn (scikit-learn): For NLP-based topic classification.

nltk or spaCy: For text preprocessing.


ğğ«ğ¨ğ£ğğœğ­ ğ’ğ­ğ«ğ®ğœğ­ğ®ğ«ğ:


â”œâ”€â”€ Scrapping.py           # Web scraping script for article extraction

â”œâ”€â”€ data_cleaning.py     # Data cleaning functions

â”œâ”€â”€ topic_classification.py # NLP-based topic classification code

â”œâ”€â”€ articles.csv         # Output dataset with cleaned and categorized articles

â”œâ”€â”€ README.md            # Project documentation

â””â”€â”€ requirements.txt     # Required libraries

Usage:

1. Web Scraping
The scraper.py script collects articles by the author across multiple pages of a specified website. It uses BeautifulSoup or Selenium to navigate and extract content.


2. Data Cleaning
The data_cleaning.py script removes unnecessary content like ads, extraneous HTML tags, and unwanted phrases from the scraped articles. It also ensures uniform formatting for fields like Title, Content, and Date.

3. Topic Classification
The topic_classification.py script uses NLP techniques to categorize each article. CountVectorizer is used for feature extraction, and Naive Bayes, SVM, or LDA is used for topic classification.

Data Cleaning:

Extracts main article content while removing ads, comments, and irrelevant text.
Normalizes text (e.g., lowercase conversion, punctuation removal).
Handles missing or malformed data and ensures structured format (title, date, content).

Topic Classification:

Converts articles to a vectorized format using CountVectorizer.
Applies classification algorithms (e.g., Naive Bayes, SVM) for supervised learning or LDA for unsupervised topic modeling.
Achieves target classification accuracy and outputs a structured dataset.


ğğ®ğ­ğ©ğ®ğ­:

The final dataset (articles.csv) includes:

Title: Title of the article.

Content: Cleaned article content.

Date: Publication date of the article.

Topic: Classified topic label.

ğŠğ§ğ¨ğ°ğ§ ğ‹ğ¢ğ¦ğ¢ğ­ğšğ­ğ¢ğ¨ğ§ğ¬:

Website Structure Changes: The scraper relies on the websiteâ€™s current HTML structure, which may change.

Model Accuracy: Topic classification model accuracy may vary based on training data volume and quality.
